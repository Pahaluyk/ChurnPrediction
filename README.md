# Отчет по проекту "Прогнозирование оттока клиентов"

## Цель проекта
Разработка модели машинного обучения для прогнозирования оттока клиентов банка на основе исторических данных. Анализ ключевых факторов, влияющих на уход клиентов.

---

## Анализ данных

### Исходные данные
- **Источник**: CSV-файл с 10,000 записей
- **Признаки**:
  - Категориальные: `Geography`, `Gender`, `HasCrCard`, `IsActiveMember`
  - Числовые: `CreditScore`, `Age`, `Tenure`, `Balance`, `NumOfProducts`, `EstimatedSalary`
- **Целевая переменная**: `Exited` (бинарная)

### Ключевые наблюдения
1. **Распределение целевой переменной**:
   - 79.6% клиентов остались (0)
   - 20.4% ушли (1)
   - Наблюдается дисбаланс классов

2. **Анализ категориальных признаков**:
   - География: 50% - Франция, 25% - Германия, 25% - Испания
   - Гендерное соотношение: 55% мужчин, 45% женщин
   - 70% клиентов имеют кредитную карту
   - 51% активных пользователей

3. **Числовые признаки**:
   - Средний возраст: 39 лет
   - Сильная корреляция оттока с возрастом (+0.29)
   - Клиенты с высоким балансом (>150,000) чаще уходят

---

## Подготовка данных

1. **Предобработка**:
   - Удалены нефункциональные столбцы: `RowNumber`, `CustomerId`, `Surname`
   - One-Hot Encoding для категориальных признаков
   - Стратифицированное разделение на train/test (80/20)

---

## Обучение моделей

### Метрика оценки: AUC-ROC
Использована кросс-валидация (5 фолдов) и GridSearch для подбора гиперпараметров.

### Результаты

| Модель           | Лучшие параметры                                  | AUC (CV) | AUC (Test) 
|-------------------|--------------------------------------------------|----------|------------|
| CatBoost          | `depth=6`, `learning_rate=0.1`, `l2_leaf_reg=3`  | 0.8690    | 0.8765      |
| XGBoost           | `max_depth=6`, `learning_rate=0.1`, `reg_lambda=3` | 0.8615    | 0.8633      | 
| Random Forest     | `max_depth=None`, `min_samples_leaf=2`, `n_estimators=300` | 0.8605    | 0.8647      | 

**Наблюдения**:
- CatBoost показал наилучший результат (AUC 0.861)
- Использование GPU ускорило обучение CatBoost и XGBoost в 2-3 раза

---

## Интерпретация модели (SHAP)

**Топ-5 факторов влияния**:
1. Возраст (Age) 
2. Баланс (Balance)
3. География (Germany)
4. Количество продуктов (NumOfProducts)
5. Активность (IsActiveMember)

**Выводы**:
- Клиенты старше 40 лет с высоким балансом склонны к оттоку
- Немецкие клиенты уходят чаще
- Использование 1-2 продуктов связано с риском ухода

---

## Заключение

1. **Лучшая модель**: CatBoost с AUC 0.861
2. **Рекомендации**:
   - Внедрить систему оповещений для клиентов старше 40 лет
   - Разработать персональные предложения для клиентов с балансом > $150K
   - Улучшить сервис для немецкого рынка
   - Стимулировать использование 3+ продуктов

3. **Дальнейшие шаги**:
   - А/B-тестирование рекомендаций
   - Мониторинг модели в production
